<html>
<head>
    <title>On Exploration and Exploitation</title>
    <link rel="stylesheet" type="text/css" href="/css/main.css">
</head>

<body>
    <nav>
        <ul>
            <li><a href="/">Home</a></li>
            <li><a href="/portfolio">Portfolio</a></li>
            <li><a href="/cv">CV</a></li>
            <li><a href="/entropy">Random</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <h1>On Exploration and Exploitation</h1>
        
        <div class="post">
            <p>Mr. Palomar believes he has figured out the secret in life. The epiphany occurred after he finished watching 6 hours of a Youtube video on AI, in which
            the narrator repeatably emphasizes building an intelligent robotic agent is all about balancing the tradeoff between exploration and exploitation. The idea 
            is extremely simple: to accumulate the maximum amount of utilities, your robotic agent has to be given sufficient amount of time to "explore" infinite amount of potential
            decisions being presented in your simulated environment; then through numerous trials and errors, the agent would have well-informed outcome predictions of performing any
            sensible actions under any given circumstance, only after which they can "exploit" the established knowledge systems of the environment, in order to always make the best-possible decisions.
            </p>
            
            <p>
            Mr. Palomar thinks this whole AI thing is simply an allegory to life itself. It aligns the common wisdom that one should always attempt to maximize one's utility in life,
            that one should explore different opportunities at an early age and learn about their outcomes, that one should pick a lane, settle down, and exploit their true passion in later life. Mr. Palomar dislikes
            the common negative connotation in the word "exploitation", because he believes the act of exploitation (of one's own option, not of the others) is actually a symbol of wisdom. It puzzled him that
            people generally wouldn't say Charles Strickland in <em>The Moon and Sixpence</em>, who determine to dedicate his life to art after giving up a more lucrative
            finance industry, is "exploitative", since people are not willing to claim becoming an artist is an exploitative act. To Mr. Palomar, however, the choice of an artist or a banker is an irrelevant
            factor to wisdom, as long as Mr. Strickland is happy, and has an honest evaluation of his own utility function.
            </p>
            
            <p>Mr. Palomar decides to build his own intelligent robotic agent using his lately gained AI expertise, since it has always been
            his dream to depict the wisest man. He believes the mainstream artistic works romanticize and emphasize the agony, beauty, and cruelty in life to an unnecessary extent,
            yet nobody is willing to tell people how to make the optimal decisions in life. He named his agent "Joi", in honor of <em>Blade Runner 2049</em>. The plan is to put Joi through countless 
            real-life simulations, in order for her to learn the ultimate trade-off between exploration and exploitation, hence informing us,
            the mortals, on how to lead our own lives. 
            
            To teach Joi the value of exploration, Mr. Palomar decides to read her <em>The Road Not Taken</em> by Robert Frost:
            </p>
            
            <blockquote>
                <p>Two roads diverged in a yellow wood,<br>
                And sorry I could not travel both;<br>
                And be one traveler, long I stood;<br>
                And looked down one as far as I could<br>
                To where it bent in the undergrowth;<br>
                Then took the other, as just as fair,<br>
                And having perhaps the better claim,<br>
                Because it was grassy and wanted wear;<br>
                Though as for that the passing there<br>
                Had worn them really about the same,<br>
                And both that morning equally lay<br>
                In leaves no step had trodden black.<br>
                Oh, I kept the first for another day!<br>
                Yet knowing how way leads on to way,<br>
                I doubted if I should ever come back.<br>
                I shall be telling this with a sigh<br>
                Somewhere ages and ages hence:<br>
                Two roads diverged in a wood, and I—<br>
                I took the one less traveled by,<br>
                And that has made all the difference.</p>
            </blockquote>
            
            <p>To teach Joi the value of exploitation and the regret of not being able to be exploitative enough in life, Mr. Palomar reads her Sylvia Plath's fig
            tree analogy in <em>The Bell Jar</em>:
            </p>
            
            <blockquote>
                <p>I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn't quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn't make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet.</p>
            </blockquote>
            
            <p>
            Like any conscientious scientist would do, Mr. Palomar comes up his own evaluation metrics to monitor Joi's progress: at the end of each real-life simulation episode, Joi
            will be given a questionnaire consisting of two questions before her death: (1) illustrate your biggest regrets; and (2) count the total number of your regrets. The first question would serve
            as a cautionary tale for Mr. Palomar's future readers, and the second question an indicator of his experimental success. Specifically, Mr. Palomar hopes to see the total numbers of Joi's regrets to be decreasing, 
            as the experiment progress. Here is a short excerpt of Mr Palomar's simulation log of Joi's lives:
            </p>
            
            <ul>
                <li><strong>Episode 0</strong>: Joi started by doing random nonsensical actions, then she decided to only eat ice-cream for the remaining of her life at age 5, and died two years after. Biggest regret: never tried Maple Syrup. Total number of regrets: 11823. <strong>Side Note</strong>: unclear what the other 11,823 regrets might be, conditional on her biggest regret is the absence of maple syrup in her life.</li>
                <li><strong>Episode 42</strong>: Joi decided to live on a tree for the remaining of her life at the age of 9, and never came down. She magically lived until 66 years old. Her biggest regret: Donna Viola. Total number of Regrets: 9777. <strong>Side Note</strong>: Donna Viola presumably is her lover, and not a surprise one can have that many regrets by living their entire life on a tree.</li>
                <li><strong>Episode 314</strong>: Joi made every rational decisions in her early year and attended Cambridge. During Cambridge, she had this afternoon routine where she spent tremendous amount of time alone philosophizing in a forest and watching the sunset, but one day she decided to commit suicide at the age of 24. Biggest Regret: Haven't learnt enough of mathematics. Total number of Regrets: 21.</li>
                <li><strong>Episode 365,427</strong>: Influenced by the works of Tao Qian, Joi decided to move to rural China to grow daisies. She formed a deep bond with the local communities by teaching English to random kids, though she was occasionally misunderstood as an American spy by the local authorities. Biggest Regret: should have also tried to grow oranges in Florida. Total number of Regrets: 3.</li>
                <li><strong>Episode 9,192,016 (ongoing)</strong>: Joi invented the aging pills, and hence solved the problem of aging. She received the Nobel Prize. Joe never dies. REGRET DATA MISSING.</li>
            </ul>
            
            <p>
            Considering the steady decrease of the number of regrets, Mr. Palomar thinks Joi has become a solid proof of concept on how to lead the regret-free life, and hence has become the wisest "man". Since Joi has solved the problem of aging in the end, she essentially has infinite horizon to live by, and therefore possesses of unbounded opportunities to eliminate all her regrets.
            He believes that Joi can help with everyone's decision-making process, as she should be able to offer guidance tailored to each person’s distinct vicissitudes in life. Despite never going through any publication process in his life,
            Mr. Palomar decides to submit his works to an academic journal. Two months later, he received the following decision letter:
            </p>
            
            <blockquote>
                <p>Dear Mr. Palomar,<br><br>
                After carefully reviewing your submission, we decided not to move forward with your work at the Journal of Artificial Intelligence for the following reasons: \
                1). Number of regrets is a wrong metrics to evaluate your agent performance. If you try to minimize regrets, Joi would simply become less explorative, and would reach a suboptimal life stage. For instance, eating candies, living on a tree, committing suicide, or becoming a farmer are all indicators of the lack of exploration spirit. \
                2). Sure the last episode is promising, but it's unclear what would happen next. Such kind of episodes also happen so rarely that you cannot claim your agent is "Joi the wisest". Your claim that "Joi possesses of unbounded opportunities to eliminate all her regrets" since she solves the againg problem is also unscientific, as it is well-known fact that one cannot decide if a computer program would eventually terminate. Hence your claim that Joi would never die is groundless.\
                3). There is no way to know whether Joi actually made the optimal decisions, or she simply lied to you about the true number of regrets when she died. \
                4). Minor suggestion: we liked your training strategy by reading Joi <em>The Road Not Taken</em> and the fig tree analogy by Sylvia Plath. But have you noticed that in almost 90% of the episodes, Joi's decisions always have something to do with plants or trees, such as her craving for maple syrup or decision to grow daisies in rural China? Perhaps more diverse readings would help. 
                <br><br>
                Sincerely,<br>
                Associate Editor
                </p>
            </blockquote>
            
            <p>
            Mr. Palomar was devastated to hear the rejection and spent the whole day binge watching <em>The Good Place</em>. Later, he realized this might not be the optimal decision given his unfortunate situation, so he decided to
            ask Joi for further guidance. It was until then that Mr. Palomar realized that Joi had stopped eating the aging pill and died at the age of 1,600, and was never reborn. The final questionnaire was left empty. Mr. Palomar hopes this is a sign that Joi feels no regret, much like Eleanor Shellstrop at the end of <em>The Good Place</em>, rather than like Truman upon realizing his entire life had been a simulation.
            </p>
        </div>
    </div>
    
    <footer>
        <ul>
            <li><a href="mailto:jiguangl@uchicago.edu">email</a></li>
        </ul>
    </footer>
</body>
</html>
