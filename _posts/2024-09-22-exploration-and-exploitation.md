<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>On Exploration and Exploitation</title>
    <link rel="stylesheet" type="text/css" href="/css/main.css">
</head>

<body>
    <nav>
        <ul>
            <li><a href="/">Home</a></li>
            <li><a href="/portfolio">Portfolio</a></li>
            <li><a href="/cv">CV</a></li>
            <li><a href="/entropy">Random</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <h1>On Exploration and Exploitation</h1>
        
        <div class="post">
            <p>Mr. Palomar believes he has figured out the secret of life. The epiphany occurred after he finished watching six hours of a YouTube video on AI, in which the narrator repeatedly emphasizes that building an intelligent robotic agent is all about balancing the trade-off between exploration and exploitation. The idea is extremely simple: to accumulate the maximum amount of utility, your robotic agent has to be given a sufficient amount of time to "explore" an infinite number of potential decisions being presented in your simulated environment; then, through numerous trials and errors, the agent would have well-informed outcome predictions for performing any sensible actions under any given circumstance, only after which it can "exploit" the established knowledge systems of the environment in order to always make the best possible decisions.</p>
            
            <p>
            Mr. Palomar thinks this whole AI thing is simply an allegory for life itself. It aligns with the common wisdom that one should always attempt to maximize one's utility in life, that one should explore different opportunities at an early age and learn about their outcomes, and that one should pick a lane, settle down, and exploit their true passion in later life. Mr. Palomar dislikes the common negative connotation of the word "exploitation" because he believes the act of exploitation (of one's own options, not of others) is actually a symbol of wisdom. It puzzled him that people generally wouldn't say Charles Strickland in <em>The Moon and Sixpence</em>, who determines to dedicate his life to art after giving up a more lucrative finance industry, is "exploitative," since people are not willing to claim becoming an artist is an exploitative act. To Mr. Palomar, however, the choice of an artist or a banker is an irrelevant factor to wisdom, as long as Mr. Strickland is happy and has an honest evaluation of his own utility function.
            </p>
            
            <p>Mr. Palomar decides to build his own intelligent robotic agent using his recently gained AI expertise, since it has always been his dream to depict the wisest man. He believes the mainstream artistic works romanticize and emphasize the agony, beauty, and cruelty in life to an unnecessary extent, yet nobody is willing to tell people how to make optimal decisions in life. He named his agent "Joi," in honor of <em>Blade Runner 2049</em>. The plan is to put Joi through countless real-life simulations in order for her to learn the ultimate trade-off between exploration and exploitation, hence informing us, the mortals, on how to lead our own lives.</p>
            
            <p>To teach Joi the value of exploration, Mr. Palomar decides to read her <em>The Road Not Taken</em> by Robert Frost:</p>
            
            <blockquote>
                <p>Two roads diverged in a yellow wood,<br>
                And sorry I could not travel both;<br>
                And be one traveler, long I stood;<br>
                And looked down one as far as I could<br>
                To where it bent in the undergrowth;<br>
                Then took the other, as just as fair,<br>
                And having perhaps the better claim,<br>
                Because it was grassy and wanted wear;<br>
                Though as for that the passing there<br>
                Had worn them really about the same,<br>
                And both that morning equally lay<br>
                In leaves no step had trodden black.<br>
                Oh, I kept the first for another day!<br>
                Yet knowing how way leads on to way,<br>
                I doubted if I should ever come back.<br>
                I shall be telling this with a sigh<br>
                Somewhere ages and ages hence:<br>
                Two roads diverged in a wood, and I—<br>
                I took the one less traveled by,<br>
                And that has made all the difference.</p>
            </blockquote>
            
            <p>To teach Joi the value of exploitation and the regret of not being able to be exploitative enough in life, Mr. Palomar reads her Sylvia Plath's fig tree analogy in <em>The Bell Jar</em>:</p>
            
            <blockquote>
                <p>I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn't quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn't make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet.</p>
            </blockquote>
            
            <p>
            Like any conscientious scientist would do, Mr. Palomar comes up with his own evaluation metrics to monitor Joi's progress: at the end of each real-life simulation episode, Joi will be given a questionnaire consisting of two questions before her death: (1) illustrate your biggest regrets; and (2) count the total number of your regrets. The first question would serve as a cautionary tale for Mr. Palomar's future readers, and the second question as an indicator of his experimental success. Specifically, Mr. Palomar hopes to see the total number of Joi's regrets decreasing as the experiment progresses. Here is a short excerpt of Mr. Palomar's simulation log of Joi's lives:
            </p>
            
            <ul>
                <li><strong>Episode 0</strong>: Joi started by doing random nonsensical actions, then she decided to only eat ice cream for the remainder of her life at age 5, and died two years after. Biggest regret: never tried maple syrup. Total number of regrets: 11,823. <strong>Side Note</strong>: Unclear what the other 11,823 regrets might be, conditional on her biggest regret being the absence of maple syrup in her life.</li>
                <li><strong>Episode 42</strong>: Joi decided to live on a tree for the remainder of her life at the age of 9 and never came down. She magically lived until 66 years old. Her biggest regret: Donna Viola. Total number of regrets: 9,777. <strong>Side Note</strong>: Donna Viola presumably is her lover, and not a surprise that one can have that many regrets by living their entire life on a tree.</li>
                <li><strong>Episode 314</strong>: Joi made every rational decision in her early years and attended Cambridge. During Cambridge, she had an afternoon routine where she spent a tremendous amount of time alone philosophizing in a forest and watching the sunset, but one day she decided to commit suicide at the age of 24. Biggest regret: Haven't learned enough mathematics. Total number of regrets: 21.</li>
                <li><strong>Episode 365,427</strong>: Influenced by the works of Tao Qian, Joi decided to move to rural China to grow daisies. She formed a deep bond with the local communities by teaching English to random kids, though she was occasionally misunderstood as an American spy by the local authorities. Biggest regret: should have also tried to grow oranges in Florida. Total number of regrets: 3.</li>
                <li><strong>Episode 9,192,016 (ongoing)</strong>: Joi invented the aging pills and hence solved the problem of aging. She received the Nobel Prize. Joi never dies. REGRET DATA MISSING.</li>
            </ul>
            
            <p>
            Considering the steady decrease in the number of regrets, Mr. Palomar thinks Joi has become solid proof of concept on how to lead a regret-free life and hence has become the wisest "man." Since Joi has solved the problem of aging in the end, she essentially has an infinite horizon to live by and therefore possesses unbounded opportunities to eliminate all her regrets. He believes that Joi can help with everyone's decision-making process, as she should be able to offer guidance tailored to each person’s distinct vicissitudes in life. Despite never going through any publication process in his life, Mr. Palomar decides to submit his work to an academic journal. Two months later, he received the following decision letter:
            </p>
            

             <blockquote>
                <p>Dear Mr. Palomar,<br><br>
                After carefully reviewing your submission, we decided not to move forward with your work at the Journal of Artificial Intelligence for the following reasons:</p>
                <ol>
                    <li><strong>The number of regrets is the wrong metric to evaluate your agent's performance.</strong> If you try to minimize regrets, Joi would simply become less explorative and would reach a suboptimal life stage. For instance, eating candies, living on a tree, committing suicide, or becoming a farmer are all indicators of a lack of exploration spirit.</li>
                    <li><strong>Sure, the last episode is promising, but it's unclear what would happen next.</strong> Such episodes also happen so rarely that you cannot claim your agent is "Joi the Wisest." Your claim that "Joi possesses unbounded opportunities to eliminate all her regrets" since she solves the aging problem is also unscientific, as it is a well-known fact that one cannot decide if a computer program would eventually terminate. Hence, your claim that Joi would never die is groundless.</li>
                    <li><strong>There is no way to know whether Joi actually made the optimal decisions or if she simply lied to you about the true number of regrets when she died.</strong></li>
                    <li><strong>Minor suggestion:</strong> We liked your training strategy of reading Joi <em>The Road Not Taken</em> and Sylvia Plath's fig tree analogy in <em>The Bell Jar</em>. But have you noticed that in almost 90% of the episodes, Joi's decisions always have something to do with plants or trees, such as her craving for maple syrup or decision to grow daisies in rural China? Perhaps more diverse readings would help.</li>
                </ol>
                <p>Sincerely,<br>
                Associate Editor</p>
            </blockquote>
            
            <p>
            Mr. Palomar was devastated to hear the rejection and spent the whole day binge-watching <em>The Good Place</em>. Later, he realized this might not be the optimal decision given his unfortunate situation, so he decided to ask Joi for further guidance. It was then that Mr. Palomar realized that Joi had stopped eating the aging pill and died at the age of 1,600, and was never reborn. The final questionnaire was left empty. Mr. Palomar hopes this is a sign that Joi feels no regret, much like Eleanor Shellstrop at the end of <em>The Good Place</em>, rather than like Truman upon realizing his entire life had been a simulation.
            </p>
        </div>
    </div>
    
    <footer>
        <ul>
            <li><a href="mailto:jiguangl@uchicago.edu">email</a></li>
        </ul>
    </footer>
</body>
</html>
